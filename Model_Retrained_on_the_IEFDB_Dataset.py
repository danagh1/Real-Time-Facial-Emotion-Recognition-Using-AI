# -*- coding: utf-8 -*-
"""Untitled23.ipynb

Automatically generated by Colaboratory.

Original file is located at
    https://colab.research.google.com/drive/1TT-Tigi4F1vv1mZNSR98lR7Wkf_tmvja

# **Real-Time Facial Emotion Recognition Using AI**

# **When Retraining the Model on the IEFDB Dataset**

# **Importing Libraries**
"""

import numpy as np
import pandas as pd
import os
import cv2
import tensorflow as tf
from tensorflow import keras
from keras.models import Sequential
from keras.models import Model
from keras import layers
from keras.utils import load_img, array_to_img, img_to_array
from keras.preprocessing.image import ImageDataGenerator
from keras.layers import Conv2D, Dense, BatchNormalization, Activation, Dropout, MaxPooling2D, Flatten
from keras.optimizers import Adam, RMSprop, SGD
from keras import regularizers
from keras.callbacks import ModelCheckpoint, CSVLogger, TensorBoard, EarlyStopping, ReduceLROnPlateau
import datetime
import seaborn as sns
from matplotlib import pyplot as plt
from keras.utils.vis_utils import plot_model
from keras.models import load_model
from keras.utils import np_utils
from sklearn.metrics import confusion_matrix, accuracy_score
from sklearn.metrics import classification_report
from sklearn.model_selection import train_test_split
from sklearn.preprocessing import StandardScaler
from zipfile import ZipFile
import zipfile
from IPython.display import display, Javascript, Image,clear_output
from google.colab.output import eval_js
from base64 import b64decode, b64encode
import PIL
import io
import html
import time  
from PIL import Image
from time import sleep

"""# **Reading the Iranian Emotional Face Database (IEFDB)**"""

with ZipFile('data.zip', 'r') as zipObj:
   # Extract all the contents of zip file in current directory
   zipObj.extractall()

# Sort list of files in the 'data' directory
data_dir = 'data'
sorted(os.listdir(data_dir))

# Counting the number of images in each subdirectory
total_images = 0
for dir_ in os.listdir(data_dir):
    count = 0
    for f in os.listdir(data_dir + "/" + dir_ + "/"):
            count += 1
            total_images += 1
    print(f"{dir_} has {count} number of images")
    
print(f"\ntotal images are {total_images}")

"""# **Preprocessing the Iranian Emotional Face Database (IEFDB)**"""

for dir_ in os.listdir(data_dir): 
  # Loop through all images in the input directory
  for f in os.listdir(data_dir + "/" + dir_ +"/"):
      # Load the image
      image = cv2.imread(data_dir + "/" + dir_ + "/" + f)
      # Crop the image by removing the parts on the left and right edges
      image = image[:, 250:725] 
      # Resize the image to 48x48 while maintaining the aspect ratio
      image = cv2.resize(image,(48,48), interpolation=cv2.INTER_AREA)
      # Convert the image to grayscale
      gray = cv2.cvtColor(image, cv2.COLOR_BGR2GRAY)
      # Save the resized image to the directory
      cv2.imwrite(os.path.join(data_dir, dir_,f), gray)

# Loading image data and labels from subdirectories into NumPy arrays
EMOTIONS = ["angry", "disgust", "fear","happy", "sad", "surprise", "neutral"]
img_arr = np.empty(shape=(total_images,48,48,3))
img_label = np.empty(shape=(total_images))
label_to_text = {}

i = 0
for e, emotion in enumerate(EMOTIONS):
    dir_ = emotion
    label_to_text[e] = dir_
    for f in os.listdir(data_dir + "/" + dir_ + "/"):
        img_arr[i] = cv2.imread(data_dir + "/" + dir_ + "/" + f)
        img_label[i] = e
        i += 1
    print(f"loaded all {dir_} images to numpy arrays")

label_to_text

"""# **Displaying the Iranian Emotional Face Database (IEFDB) Images**"""

fig = plt.figure(1, (10,10))
idx = 0
for k in label_to_text:
    sample_indices = np.random.choice(np.where(img_label==k)[0], size=7, replace=False)
    sample_images = img_arr[sample_indices]
    for img in sample_images:
        idx += 1
        ax = plt.subplot(7,7,idx)
        ax.imshow(img[:,:,0], cmap='gray')
        ax.set_xticks([])
        ax.set_yticks([])
        ax.set_title(label_to_text[k])
        plt.tight_layout()

# Converting the categorical labels of an image dataset into one-hot encoded arrays then print the shape of the resulting array
img_label = np_utils.to_categorical(img_label)
img_label.shape

# Scale data and returns the maximum value in the img_arr array after normalization
img_arr = img_arr / 255.
img_arr.max()

"""# **Splitting the Iranian Emotional Face Database (IEFDB) into Train, Test, and Valid Sets**"""

# Split data into 80% training and 20% testing
X_train, X_test, y_train, y_test = train_test_split(img_arr, img_label, shuffle=True, test_size=0.2, random_state=42)

# Split training data into 80% training and 20% validation
X_train, X_val, y_train, y_val = train_test_split(X_train, y_train, test_size=0.2, random_state=42)

# Checking shapes
X_train.shape, X_test.shape, y_train.shape, y_test.shape, X_val.shape, X_test.shape, y_val.shape, y_test.shape

"""# **Reading the Hybrid Dataset that Contains the Three Datasets (IEFDB, CK+, JAFFE)**"""

with ZipFile('alldataset.zip', 'r') as zipObj:
   # Extract all the contents of zip file in current directory
   zipObj.extractall()

# Sort list of files in the 'alldataset' directory
data_dir4 = 'alldataset'
sorted(os.listdir(data_dir4))

# Counting the number of images in each subdirectory
total_images4 = 0
for dir_4 in os.listdir(data_dir4):
    count = 0
    for f4 in os.listdir(data_dir4 + "/" + dir_4 + "/"):
            count += 1
            total_images4 += 1
    print(f"{dir_4} has {count} number of images")
    
print(f"\ntotal images are {total_images4}")

"""# **Preprocessing the Hybrid Dataset**"""

# Loading image data and labels from subdirectories into NumPy arrays
EMOTIONS = ["angry", "disgust", "fear","happy", "sad", "surprise", "neutral"]
img_arr2 = np.empty(shape=(total_images4,48,48,3))
img_label2 = np.empty(shape=(total_images4))
label_to_text2 = {}

j = 0
for n, emotion in enumerate(EMOTIONS):
    dir_4 = emotion
    label_to_text2[n] = dir_4
    for f4 in os.listdir(data_dir4 + "/" + dir_4 + "/"):
        img_arr2[j] = cv2.imread(data_dir4 + "/" + dir_4 + "/" + f4)
        img_label2[j] = n
        j += 1
    print(f"loaded all {dir_4} images to numpy arrays")

label_to_text2

"""# **Displaying the Hybrid Dataset Images**"""

fig2 = plt.figure(1, (10,10))
idx = 0
for z in label_to_text2:
    sample_indices2 = np.random.choice(np.where(img_label2==z)[0], size=7, replace=False)
    sample_images2 = img_arr2[sample_indices2]
    for img in sample_images2:
        idx += 1
        ax = plt.subplot(7,7,idx)
        ax.imshow(img[:,:,0], cmap='gray')
        ax.set_xticks([])
        ax.set_yticks([])
        ax.set_title(label_to_text2[z])
        plt.tight_layout()

# Converting the categorical labels of an image dataset into one-hot encoded arrays then print the shape of the resulting array
img_label2 = np_utils.to_categorical(img_label2)
img_label2.shape

# Scale data and returns the maximum value in the img_arr2 array after normalization
img_arr2 = img_arr2 / 255.
img_arr2.max()

"""# **Splitting the Hybrid Dataset into Train, Test, and Valid Sets**"""

# Split data into 80% training and 20% testing
X_train2, X_test2, y_train2, y_test2 = train_test_split(img_arr2, img_label2, shuffle=True, test_size=0.2, random_state=42)

# Split training data into 80% training and 20% validation
X_train2, X_val2, y_train2, y_val2 = train_test_split(X_train2, y_train2, test_size=0.2, random_state=42)

# Checking shapes
X_train2.shape, X_test2.shape, y_train2.shape, y_test2.shape, X_val2.shape, X_test2.shape, y_val2.shape, y_test2.shape

"""# **Load the Pre-trained Model**"""

# Load the pre-trained model architecture
fermodel = load_model('kaggle_model.h5')
fermodel.summary()

# Plotting architecture of defined model
keras.utils.plot_model(fermodel, to_file='fermodel.png', show_shapes=True, show_layer_names=True)

"""# **Compiling the Model**"""

batch_size = 40
epochs = 400

optims = [
    keras.optimizers.Nadam(learning_rate=0.001, beta_1=0.9, beta_2=0.999, epsilon=1e-07),
    keras.optimizers.Adam(0.01),
]

fermodel.compile(
        loss='categorical_crossentropy',
        optimizer=optims[1],
        metrics=['accuracy']
)

"""# **Evaluating the Model's Loss and Accuracy on the Iranian Emotional Face Testing Dataset Before Retraining the Model**"""

test_model_loss, test_model_accu = fermodel.evaluate(X_test, y_test)
print("test accuracy = {:.2f}".format(test_model_accu*100))

"""# **Evaluating the Model's Loss and Accuracy on the Testing Dataset that Contains the Three Datasets Before Retraining the Model**"""

test_model_loss2, test_model_accu2 = fermodel.evaluate(X_test2, y_test2)
print("test accuracy = {:.2f}".format(test_model_accu2*100))

"""# **Training the Model on the Iranian Emotional Face Database (IEFDB)**"""

# Defining two callback functions 'EarlyStopping', 'ReduceLROnPlateau' and creating a list 'callbacks' to hold these functions
early_stopping = EarlyStopping(
    monitor='val_accuracy',
    min_delta=0.00008,
    patience=20,
    verbose=1,
    restore_best_weights=True,
)

lr_scheduler = ReduceLROnPlateau(
    monitor='val_accuracy',
    min_delta=0.0001,
    factor=0.1,
    patience=4,
    min_lr=1e-7,
    verbose=1,
)

callbacks = [
    early_stopping,
    lr_scheduler
]

# Fitting the CNN model
history = fermodel.fit(X_train, y_train, batch_size=batch_size,
    steps_per_epoch=len(X_train) / batch_size,
    epochs=epochs,
    callbacks=callbacks,
    use_multiprocessing=True,
    validation_data=(X_val, y_val))

"""# **Evaluating the Model's Loss and Accuracy on the Testing, Training, and Validation Sets for the Iranian Emotional Face Dataset After Retraining the Model**"""

train_model_loss_new, train_model_accu_new = fermodel.evaluate(X_train, y_train)
test_model_loss_new, test_model_accu_new = fermodel.evaluate(X_test, y_test)
print("train accuracy = {:.2f} , test accuracy = {:.2f}".format(train_model_accu_new*100, test_model_accu_new*100))

val_model_loss_new, val_model_accu_new = fermodel.evaluate(X_val, y_val)
print("valid accuracy = {:.2f}".format( val_model_accu_new*100))

"""# **Evaluating the Model's Loss and Accuracy on the Hybrid Testing Dataset After Retraining the Model**"""

test_model_loss_new2, test_model_accu_new2 = fermodel.evaluate(X_test2, y_test2)
print("test accuracy = {:.2f}".format( test_model_accu_new2*100))

"""# **Save the Retrained Model**"""

# Save best Model
fermodel.save("pretrainedferbestmodel.h5")

# Saving model in json format along with weights
fer_json = fermodel.to_json()  
with open("pretrainedferbestmodelweight.json", "w") as json_file:  
    json_file.write(fer_json)  
fermodel.save_weights("pretrainedferbestmodelweight.h5")

"""# **Plotting Accuracy & Loss**"""

plt.figure(figsize=(14,5))
plt.subplot(1,2,1)
plt.plot(history.history['accuracy'])
plt.plot(history.history['val_accuracy'])
plt.title('Model Accuracy')
plt.xlabel('Epochs')
plt.ylabel('Accuracy')
plt.legend(['train', 'valid'], loc='upper left')

plt.subplot(1,2,2)
plt.plot(history.history['loss'])
plt.plot(history.history['val_loss'])
plt.title('Model Loss')
plt.xlabel('Epochs')
plt.ylabel('Loss')
plt.legend(['train', 'valid'], loc='upper left')

plt.savefig('history100.png')
plt.show()

"""# **Confusion Matrix for the Iranian Emotional Face Test Set**"""

# Generate predictions on the test data
y_pred = fermodel.predict(X_test)
# Convert predictions to class labels
y_pred_classes = np.argmax(y_pred, axis=1)
# Convert true labels to class labels
y_test_classes = np.argmax(y_test, axis=1)

# Compute the confusion matrix
conf_matrix = confusion_matrix(y_test_classes, y_pred_classes)
print("FER confusion matrix")
print(conf_matrix,'\n')
# Plot the confusion matrix as an image
plt.imshow(conf_matrix, cmap=plt.cm.Blues)

# Add title and axis labels
plt.title("FER Confusion Matrix")
plt.xlabel("Predicted Labels")
plt.ylabel("True Labels")

# Add tick marks and class labels on the axes
tick_marks = np.arange(7)
class_labels = ["angry", "disgust", "fear", "happy", "sad", "surprise", "neutral"]
plt.xticks(tick_marks, class_labels, rotation=50)
plt.yticks(tick_marks, class_labels)

# Add data labels in each cell
threshold = conf_matrix.max() / 2.
for i, j in np.ndindex(conf_matrix.shape):
    plt.text(j, i, conf_matrix[i, j], ha="center", va="center", color="white" if conf_matrix[i, j] > threshold else "black")

# Add color bar
plt.colorbar()
# Save the plot to a file
plt.savefig("confusion_matrix3.png")
# Show the plot
plt.show()

"""# **Classification Report for the Iranian Emotional Face Test Set**"""

report = classification_report(y_test_classes, y_pred_classes)
print(report)